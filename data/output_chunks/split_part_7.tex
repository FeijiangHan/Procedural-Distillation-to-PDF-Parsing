\section{Limitation}
%
In this work, we provide an experimental analysis of how CoT works. We focus specifically on manipulating the reasoning steps in CoT prompts and measuring the impact on model performance. However, we did not deeply analyze the underlying mechanisms behind why increasing reasoning steps improves performance. This includes either theoretical analysis or explainability analysis to analyze the internal workings of LLMs, and further investigation could provide more insight. Additionally, our study was limited to certain datasets and models like GPT-3.5 and GPT-4. Testing on more diverse tasks and newer models could reveal different trends.

\bibliography{custom}
\clearpage
\appendix

\onecolumn